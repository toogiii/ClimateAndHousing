{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project 1 Development Notebook: Climate and Housing</h1>\n",
    "<p>\n",
    "This file contains development code for project 1 for ECON 1680. It contains all code required to replicate the results outlined in the draft. Inline citations are included for all code segments that are not original. The code first cleans the data, generates some descriptive statistics, and then leverages the methodology discussed in the paper: \n",
    "We use different regressions and dimension reduction techniques to analyze the relationship between climate risk and housing prices, using space as our source of variation.\n",
    "</p>\n",
    "<h2>1. Imports and Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvg\\AppData\\Local\\Temp\\ipykernel_22768\\1605783651.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date(string):\n",
    "    # From https://stackoverflow.com/questions/25341945/check-if-string-has-date-any-format\n",
    "    # Checks if a string can be interpreted as a date\n",
    "    try:\n",
    "        parse(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Data: Cleaning and Saving</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to production directory: note that you must include Data, Figures, and Code subdirectories.\n",
    "path = \"C:\\\\Users\\\\garvg\\\\Downloads\\\\Project 1\\\\\"\n",
    "\n",
    "# Read in CSV data\n",
    "zillow = pd.read_csv(path + \"Data\\\\zillow.csv\")\n",
    "nri_fema = pd.read_csv(path + \"Data\\\\nri_fema.csv\")\n",
    "oi_covars = pd.read_csv(path + \"Data\\\\oi_covars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CSV data by State and County FIPS codes and save\n",
    "clim_hous_data = zillow.merge(nri_fema, on=[\"state_fips\", \"county_fips\"], validate=\"one_to_one\")\n",
    "all_data = clim_hous_data.merge(oi_covars, on=[\"state_fips\", \"county_fips\"], validate=\"one_to_one\")\n",
    "all_data.to_csv(path + \"Data\\\\all_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to keep: hazard scores, controls, and house value\n",
    "hazard_vars = [\n",
    "    \"Avalanche\", \"Coastal Flooding\", \"Cold Wave\", \"Drought\", \"Earthquake\", \n",
    "    \"Hail\", \"Heat Wave\", \"Hurricane\", \"Ice Storm\", \"Landslide\", \"Lightning\",\n",
    "    \"Riverine Flooding\", \"Strong Wind\", \"Tornado\", \"Tsunami\", \"Volcanic Activity\",\n",
    "    \"Wildfire\", \"Winter Weather\"]\n",
    "hazard_vars = [hazard + \" - Hazard Type Risk Index Score\" for hazard in hazard_vars]\n",
    "\n",
    "housing_vars = [col for col in all_data.columns if is_date(col)]\n",
    "\n",
    "control_vars = [\n",
    "    \"Population (2020)\", \"Building Value ($)\", \"Agriculture Value ($)\", \"Area (sq mi)\", \"job_density_2013\",\n",
    "    \"ann_avg_job_growth_2004_2013\", \"ln_wage_growth_hs_grad\", \"emp2000\", \"foreign_share2010\", \n",
    "    \"mean_commutetime2000\", \"frac_coll_plus2000\", \"frac_coll_plus2010\", \"hhinc_mean2000\",\n",
    "    \"med_hhinc1990\", \"med_hhinc2016\", \"poor_share1990\", \"poor_share2000\", \"poor_share2010\",\n",
    "    \"share_white2000\", \"share_black2000\", \"share_hisp2000\", \"share_asian2000\",\n",
    "    \"share_white2010\", \"share_black2010\", \"share_hisp2010\", \"share_asian2010\"\n",
    "    ]\n",
    "\n",
    "columns = [\n",
    "    \"State Name\", \"County Name\", \"state_fips\", \"county_fips\"]\n",
    "columns.extend(hazard_vars)\n",
    "columns.extend(housing_vars)\n",
    "columns.extend(control_vars)\n",
    "\n",
    "all_data_pruned = all_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvg\\AppData\\Local\\Temp\\ipykernel_22768\\518953060.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_pruned[hazard] = all_data_pruned[hazard].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# For hazard data, rename variables and replace missing values with zeroes:\n",
    "#   Missing values imply that the area has had no instances of a given hazard\n",
    "#   or has never deemed that hazard a threat to life or property. We can roughly\n",
    "#   infer that missing values imply perceived invulnerability to a given hazard.\n",
    "\n",
    "hazard_rename_dict = dict()\n",
    "for hazard in hazard_vars:\n",
    "    hazard_rename_dict[hazard] = hazard[:hazard.index(\" - \")]\n",
    "    all_data_pruned[hazard] = all_data_pruned[hazard].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data after cleaning\n",
    "all_data_pruned.to_csv(path + \"Data\\\\all_data_pruned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Descriptive Statistics</h2>\n",
    "<p>Note: After running the above code, we may always start here since the pre-processing steps are saved in the all_data_pruned.csv file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>Avalanche - Hazard Type Risk Index Score</th>\n",
       "      <th>Coastal Flooding - Hazard Type Risk Index Score</th>\n",
       "      <th>Cold Wave - Hazard Type Risk Index Score</th>\n",
       "      <th>Drought - Hazard Type Risk Index Score</th>\n",
       "      <th>Earthquake - Hazard Type Risk Index Score</th>\n",
       "      <th>Hail - Hazard Type Risk Index Score</th>\n",
       "      <th>...</th>\n",
       "      <th>poor_share2000</th>\n",
       "      <th>poor_share2010</th>\n",
       "      <th>share_white2000</th>\n",
       "      <th>share_black2000</th>\n",
       "      <th>share_hisp2000</th>\n",
       "      <th>share_asian2000</th>\n",
       "      <th>share_white2010</th>\n",
       "      <th>share_black2010</th>\n",
       "      <th>share_hisp2010</th>\n",
       "      <th>share_asian2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>33.653846</td>\n",
       "      <td>43.259557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.846643</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48.106904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177636</td>\n",
       "      <td>0.157657</td>\n",
       "      <td>0.317937</td>\n",
       "      <td>0.100307</td>\n",
       "      <td>0.439193</td>\n",
       "      <td>0.105664</td>\n",
       "      <td>0.277873</td>\n",
       "      <td>0.089271</td>\n",
       "      <td>0.477450</td>\n",
       "      <td>0.121261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Cook</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.265594</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.949093</td>\n",
       "      <td>96.659243</td>\n",
       "      <td>93.923003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126334</td>\n",
       "      <td>0.152655</td>\n",
       "      <td>0.498122</td>\n",
       "      <td>0.242277</td>\n",
       "      <td>0.196171</td>\n",
       "      <td>0.046331</td>\n",
       "      <td>0.438595</td>\n",
       "      <td>0.249698</td>\n",
       "      <td>0.239623</td>\n",
       "      <td>0.056553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Harris</td>\n",
       "      <td>48</td>\n",
       "      <td>201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.843058</td>\n",
       "      <td>99.204582</td>\n",
       "      <td>88.450525</td>\n",
       "      <td>90.741330</td>\n",
       "      <td>94.050270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135599</td>\n",
       "      <td>0.165664</td>\n",
       "      <td>0.451573</td>\n",
       "      <td>0.176150</td>\n",
       "      <td>0.307376</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>0.329789</td>\n",
       "      <td>0.189457</td>\n",
       "      <td>0.408444</td>\n",
       "      <td>0.051969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.841553</td>\n",
       "      <td>98.218263</td>\n",
       "      <td>99.331849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109395</td>\n",
       "      <td>0.139750</td>\n",
       "      <td>0.672659</td>\n",
       "      <td>0.037874</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.017987</td>\n",
       "      <td>0.586845</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>0.295705</td>\n",
       "      <td>0.030152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>32.796781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.564111</td>\n",
       "      <td>99.745466</td>\n",
       "      <td>22.589882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119072</td>\n",
       "      <td>0.124306</td>\n",
       "      <td>0.555414</td>\n",
       "      <td>0.060665</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.083679</td>\n",
       "      <td>0.484619</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.320274</td>\n",
       "      <td>0.098978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Name  County Name  state_fips  county_fips  \\\n",
       "0  California  Los Angeles           6           37   \n",
       "1    Illinois         Cook          17           31   \n",
       "2       Texas       Harris          48          201   \n",
       "3     Arizona     Maricopa           4           13   \n",
       "4  California    San Diego           6           73   \n",
       "\n",
       "   Avalanche - Hazard Type Risk Index Score  \\\n",
       "0                                 33.653846   \n",
       "1                                  0.000000   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                                 31.250000   \n",
       "\n",
       "   Coastal Flooding - Hazard Type Risk Index Score  \\\n",
       "0                                        43.259557   \n",
       "1                                        44.265594   \n",
       "2                                        73.843058   \n",
       "3                                         0.000000   \n",
       "4                                        32.796781   \n",
       "\n",
       "   Cold Wave - Hazard Type Risk Index Score  \\\n",
       "0                                  0.000000   \n",
       "1                                100.000000   \n",
       "2                                 99.204582   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   Drought - Hazard Type Risk Index Score  \\\n",
       "0                               73.846643   \n",
       "1                               19.949093   \n",
       "2                               88.450525   \n",
       "3                               85.841553   \n",
       "4                               89.564111   \n",
       "\n",
       "   Earthquake - Hazard Type Risk Index Score  \\\n",
       "0                                 100.000000   \n",
       "1                                  96.659243   \n",
       "2                                  90.741330   \n",
       "3                                  98.218263   \n",
       "4                                  99.745466   \n",
       "\n",
       "   Hail - Hazard Type Risk Index Score  ...  poor_share2000  poor_share2010  \\\n",
       "0                            48.106904  ...        0.177636        0.157657   \n",
       "1                            93.923003  ...        0.126334        0.152655   \n",
       "2                            94.050270  ...        0.135599        0.165664   \n",
       "3                            99.331849  ...        0.109395        0.139750   \n",
       "4                            22.589882  ...        0.119072        0.124306   \n",
       "\n",
       "   share_white2000  share_black2000  share_hisp2000  share_asian2000  \\\n",
       "0         0.317937         0.100307        0.439193         0.105664   \n",
       "1         0.498122         0.242277        0.196171         0.046331   \n",
       "2         0.451573         0.176150        0.307376         0.045832   \n",
       "3         0.672659         0.037874        0.243300         0.017987   \n",
       "4         0.555414         0.060665        0.260778         0.083679   \n",
       "\n",
       "   share_white2010  share_black2010  share_hisp2010  share_asian2010  \n",
       "0         0.277873         0.089271        0.477450         0.121261  \n",
       "1         0.438595         0.249698        0.239623         0.056553  \n",
       "2         0.329789         0.189457        0.408444         0.051969  \n",
       "3         0.586845         0.054242        0.295705         0.030152  \n",
       "4         0.484619         0.055997        0.320274         0.098978  \n",
       "\n",
       "[5 rows x 337 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "working_data = pd.read_csv(path + \"Data\\\\all_data_pruned.csv\")\n",
    "working_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write means and variances to logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate map of hazard risk\n",
    "\n",
    "# Generate map of housing prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time trend of housing prices\n",
    "\n",
    "# Generate time trend of housing price variance per year\n",
    "\n",
    "# Generate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
